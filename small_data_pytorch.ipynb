{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative and DL techniques on small metabolic engineering datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERG8</th>\n",
       "      <th>ERG10</th>\n",
       "      <th>ERG12</th>\n",
       "      <th>ERG13</th>\n",
       "      <th>ERG19</th>\n",
       "      <th>ERG20</th>\n",
       "      <th>IDI1</th>\n",
       "      <th>tHMG1</th>\n",
       "      <th>prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.862946</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>0.892209</td>\n",
       "      <td>0.909210</td>\n",
       "      <td>0.848096</td>\n",
       "      <td>0.840536</td>\n",
       "      <td>0.829163</td>\n",
       "      <td>0.753874</td>\n",
       "      <td>3.739360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.783979</td>\n",
       "      <td>1.001960</td>\n",
       "      <td>0.978865</td>\n",
       "      <td>0.916151</td>\n",
       "      <td>0.718987</td>\n",
       "      <td>0.827099</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>0.770533</td>\n",
       "      <td>2.448719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870862</td>\n",
       "      <td>0.796111</td>\n",
       "      <td>1.096750</td>\n",
       "      <td>0.919447</td>\n",
       "      <td>0.770546</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>0.956943</td>\n",
       "      <td>0.909107</td>\n",
       "      <td>2.454255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ERG8     ERG10     ERG12     ERG13     ERG19     ERG20      IDI1  \\\n",
       "0  0.862946  0.987876  0.892209  0.909210  0.848096  0.840536  0.829163   \n",
       "1  0.783979  1.001960  0.978865  0.916151  0.718987  0.827099  0.960778   \n",
       "2  0.870862  0.796111  1.096750  0.919447  0.770546  0.879257  0.956943   \n",
       "\n",
       "      tHMG1      prod  \n",
       "0  0.753874  3.739360  \n",
       "1  0.770533  2.448719  \n",
       "2  0.909107  2.454255  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Working on {device}')\n",
    "\n",
    "DATA_PATH = './data/carotenoid_production.csv'\n",
    "\n",
    "df_base = pd.read_csv('./data/carotenoid_production.csv')\n",
    "cols = df_base.columns\n",
    "df_base.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def load_and_standardize_data(path=DATA_PATH):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.values.reshape(-1, df.shape[1]).astype('float32')\n",
    "    X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)   \n",
    "    return X_train, X_test, scaler\n",
    "\n",
    "class DataBuilder(Dataset):\n",
    "    def __init__(self, path, train=True):\n",
    "        self.X_train, self.X_test, self.standardizer = load_and_standardize_data(DATA_PATH)\n",
    "        if train:\n",
    "            self.x = torch.from_numpy(self.X_train)\n",
    "            self.len=self.x.shape[0]\n",
    "        else:\n",
    "            self.x = torch.from_numpy(self.X_test)\n",
    "            self.len=self.x.shape[0]\n",
    "        del self.X_train\n",
    "        del self.X_test \n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_set=DataBuilder(DATA_PATH, train=True)\n",
    "testdata_set=DataBuilder(DATA_PATH, train=False)\n",
    "\n",
    "trainloader=DataLoader(dataset=traindata_set,batch_size=1024)\n",
    "testloader=DataLoader(dataset=testdata_set,batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE for generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, D_in, H=50, H2=12, latent_dim=3):\n",
    "        \n",
    "        # Encoder\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2 = nn.Linear(H, H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3 = nn.Linear(H2, H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "        \n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "        \n",
    "#         # Decoder\n",
    "        self.linear4=nn.Linear(H2,H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5=nn.Linear(H2,H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6=nn.Linear(H,D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "        \n",
    "        return r1, r2\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # self.decode(z) ist sp√§ter recon_batch, mu ist mu und logvar ist logvar\n",
    "        return self.decode(z), mu, logvar  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    # x_recon ist der im forward im Model erstellte recon_batch, x ist der originale x Batch, mu ist mu und logvar ist logvar \n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD\n",
    "    \n",
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = traindata_set.x.shape[1]\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = Autoencoder(D_in, H, H2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_mse = customLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    if epoch % 200 == 0:        \n",
    "        print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "        \n",
    "def test(epoch):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            if epoch % 200 == 0:        \n",
    "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "                    epoch, test_loss / len(testloader.dataset)))\n",
    "            test_losses.append(test_loss / len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 200 Average training loss: 10.3517\n",
      "====> Epoch: 200 Average test loss: 11.6422\n",
      "====> Epoch: 400 Average training loss: 8.1159\n",
      "====> Epoch: 400 Average test loss: 9.2272\n",
      "====> Epoch: 600 Average training loss: 6.6655\n",
      "====> Epoch: 600 Average test loss: 8.4034\n",
      "====> Epoch: 800 Average training loss: 6.3386\n",
      "====> Epoch: 800 Average test loss: 8.6102\n",
      "====> Epoch: 1000 Average training loss: 5.7577\n",
      "====> Epoch: 1000 Average test loss: 8.9381\n",
      "====> Epoch: 1200 Average training loss: 5.7880\n",
      "====> Epoch: 1200 Average test loss: 8.4799\n",
      "====> Epoch: 1400 Average training loss: 5.3308\n",
      "====> Epoch: 1400 Average test loss: 8.3497\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(testloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of SDV library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/WUR/g0012069/env/main/lib/python3.10/site-packages/sdv/single_table/base.py:82: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sdv.single_table import TVAESynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(norm_df)\n",
    "\n",
    "synthesizer = TVAESynthesizer(metadata=metadata)\n",
    "synthesizer.fit(norm_df)                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERG8</th>\n",
       "      <th>ERG10</th>\n",
       "      <th>ERG12</th>\n",
       "      <th>ERG13</th>\n",
       "      <th>ERG19</th>\n",
       "      <th>ERG20</th>\n",
       "      <th>IDI1</th>\n",
       "      <th>tHMG1</th>\n",
       "      <th>prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066514</td>\n",
       "      <td>0.054399</td>\n",
       "      <td>0.126596</td>\n",
       "      <td>0.039659</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.092553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093299</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.064818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037197</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.110722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059838</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.040918</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.047966</td>\n",
       "      <td>0.022182</td>\n",
       "      <td>0.102767</td>\n",
       "      <td>0.302988</td>\n",
       "      <td>0.304479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031051</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.040085</td>\n",
       "      <td>0.062605</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.139239</td>\n",
       "      <td>0.175938</td>\n",
       "      <td>0.320288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036987</td>\n",
       "      <td>0.030018</td>\n",
       "      <td>0.032771</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.038957</td>\n",
       "      <td>0.031745</td>\n",
       "      <td>0.196248</td>\n",
       "      <td>0.152017</td>\n",
       "      <td>0.474011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.127770</td>\n",
       "      <td>0.056158</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>0.071138</td>\n",
       "      <td>0.044124</td>\n",
       "      <td>0.153436</td>\n",
       "      <td>0.246194</td>\n",
       "      <td>0.229355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040882</td>\n",
       "      <td>0.032803</td>\n",
       "      <td>0.058818</td>\n",
       "      <td>0.046002</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121529</td>\n",
       "      <td>0.111871</td>\n",
       "      <td>0.281619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.172320</td>\n",
       "      <td>0.029344</td>\n",
       "      <td>0.378335</td>\n",
       "      <td>0.186857</td>\n",
       "      <td>0.038486</td>\n",
       "      <td>0.053219</td>\n",
       "      <td>0.119888</td>\n",
       "      <td>0.315523</td>\n",
       "      <td>0.530606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.408432</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>0.125073</td>\n",
       "      <td>0.047979</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.214757</td>\n",
       "      <td>0.197110</td>\n",
       "      <td>0.329822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.114154</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134829</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0.141293</td>\n",
       "      <td>0.234177</td>\n",
       "      <td>0.300122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ERG8     ERG10     ERG12     ERG13     ERG19     ERG20      IDI1  \\\n",
       "0  0.066514  0.054399  0.126596  0.039659  0.016332  0.018851  0.092553   \n",
       "1  0.093299  0.046963  0.064818  0.000000  0.037197  0.008480  0.110722   \n",
       "2  0.059838  0.068441  0.040918  0.053370  0.047966  0.022182  0.102767   \n",
       "3  0.031051  0.022088  0.040085  0.062605  0.039939  0.008735  0.139239   \n",
       "4  0.036987  0.030018  0.032771  0.077922  0.038957  0.031745  0.196248   \n",
       "5  0.127770  0.056158  0.096500  0.208214  0.071138  0.044124  0.153436   \n",
       "6  0.040882  0.032803  0.058818  0.046002  0.042203  0.000000  0.121529   \n",
       "7  0.172320  0.029344  0.378335  0.186857  0.038486  0.053219  0.119888   \n",
       "8  0.408432  0.052148  0.125073  0.047979  0.025489  0.037053  0.214757   \n",
       "9  0.114154  0.067031  0.000000  0.134829  0.035225  0.032623  0.141293   \n",
       "\n",
       "      tHMG1      prod  \n",
       "0  0.000000  0.210543  \n",
       "1  0.000000  0.079038  \n",
       "2  0.302988  0.304479  \n",
       "3  0.175938  0.320288  \n",
       "4  0.152017  0.474011  \n",
       "5  0.246194  0.229355  \n",
       "6  0.111871  0.281619  \n",
       "7  0.315523  0.530606  \n",
       "8  0.197110  0.329822  \n",
       "9  0.234177  0.300122  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data = synthesizer.sample(num_rows=10)\n",
    "synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
